---
title: "IRL-VLA: Training an Vision-Language-Action Policy via Reward World Model for End-to-End Autonomous Driving"
collection: publications
category: manuscripts
permalink: /publication/2025-0815-Diffvla
teaser: '/images/papers/2025_irlvla.png'
excerpt: 'DiffVLA a novel hybrid sparse-dense diffusion policy, empowered by a Vision-Language Model (VLM), called Diff-VLA. We explore the sparse diffusion representation for efficient multi-modal driving behavior.'
date: 2025-08-15
paperurl: 'https://arxiv.org/pdf/2508.06571'
codeurl: 'https://github.com/IRL-VLA/IRL-VLA'
# projecturl: 'https://diffvla.github.io/'
citation: 'Jiang, Anqing, et al. "Diffvla: Vision-language guided diffusion planning for autonomous driving." arXiv preprint arXiv:2505.19381 (2025).'
journal: 'ArXiv'
---
